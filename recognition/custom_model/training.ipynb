{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.regularizers import l2 # type: ignore\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_subfolders(base_folder, img_size=(32, 32), augment=False):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Define data augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    for label in os.listdir(base_folder):\n",
    "        label_folder = os.path.join(base_folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for filename in os.listdir(label_folder):\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "                    img = Image.open(os.path.join(label_folder, filename)).convert('RGB')\n",
    "                    img = img.resize(img_size)\n",
    "                    img_array = np.array(img)\n",
    "                    img_array = np.expand_dims(img_array, 0)  # Expand dimensions to match input shape\n",
    "\n",
    "                    # Apply data augmentation if augment flag is True\n",
    "                    if augment:\n",
    "                        augmented_images = datagen.flow(img_array, batch_size=1)\n",
    "                        for _ in range(5):  # Generate 5 augmented images for each original image\n",
    "                            aug_img = next(augmented_images)[0].astype(np.uint8)\n",
    "                            images.append(aug_img)\n",
    "                            labels.append(label)\n",
    "                    else:\n",
    "                        images.append(img_array[0])\n",
    "                        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "base_folder = 'datasets'\n",
    "img_size = (36, 36) \n",
    "images, labels = load_images_from_subfolders(base_folder, img_size, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "onehot_labels = to_categorical(labels)  # Convert to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_array):\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.show()\n",
    "\n",
    "def rgb_to_grayscale(images):\n",
    "    grayscale_images = np.dot(images[...,:3], [0.299, 0.587, 0.114])\n",
    "    return grayscale_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32') / 255.0\n",
    "grayscale_images = rgb_to_grayscale(images)  # Add channel dimensio\n",
    "grayscale_images = np.expand_dims(grayscale_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(grayscale_images, onehot_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAH0klEQVR4nO3du47OXxuAYcOfKewqIiFBbEIkKmoJHVpHoFBplI5AKXEEWqUjEBFTTCQoCQWZZBCbIBIJ3q+7E81nmRkzzFxX/WS9q7vzFOv3Tk0mk8k6AFi3bt36lb4AAH8PUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACD/rfQF1prJZDI09/z58+Ez9+zZMzQ3PT09fCawNtkUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADI1GT0iS1LYn5+fmju2LFjw2fevHlzaO78+fPDZwJrk00BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgD5b6UvsNa8f/9+aO7du3fDZ27cuHGh1wH4iU0BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYB40bzMnjx5MjS3fv14r/fv37/Q6wD8xKYAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEC8aF5md+7cGZrbt2/f8JleNANLxaYAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYD4zMUyu3fv3tDcyZMnh8/cuHHjQq8D8BObAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8aJ5iTx9+nRo7tGjR0Nzly9fXsx1ABbEpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQLxoXiIzMzNLet7p06eX9DyAETYFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDiRfMSuX///tDc3r17h+Z27ty5mOsALIhNAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8ZmLJTIzMzM0d+rUqaG5TZs2LeY6y+bWrVtDc58+fRqau3jx4mKuAyySTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgHjR/AufP38empufnx+aO3To0GKusyy+fv06PHvlypWhuaNHjw7NedEMK8umAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAvGj+hTdv3gzNvX37dmjuyJEji7nOspidnR2enZubG5q7evXqQq8DLCObAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA4jMXv/Ds2bOhue/fvw/NPX78eGjux48fQ3O/48WLF0NzN27cGD5z165dQ3MXLlwYPhNYOTYFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDiRfMvbN++fWjuwIEDQ3PXrl0bmht9If07NmzYMDT35cuX4TMvXbo0NLdjx47hM4GVY1MAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACBTk8lkstKXWA0+f/48NPfhw4c/e5H/Y/T/ps+cOTN85u3bt4fmzp49O3wmsHJsCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxH80L5EtW7Ys6dyf8PTp0yU/8+DBg0t+JrBybAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIjPXKwhr169GprbtGnT8Jnbtm1b6HWAv5BNAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAeNG8hszNzQ3Nbd68efjMLVu2LPQ6wF/IpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQLxoXkNmZ2eH5g4ePDh85u+8fgb+fjYFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQDiRfMq8O3bt6G5Bw8eDM2dO3du+LenpqaGZ4G/n00BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDxmYtV4PXr10NzL1++HJo7ceLEYq4D/MNsCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxIvmVeDx48dDc1+/fh2aO378+GKuA/zDbAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAMSL5lXg7t27Q3O7d+8emjt8+PBirgP8w2wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIz1ysAh8/fhya27p169Dc9PT0Yq4D/MNsCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxIvmVeDhw4dDc0eOHBmam5qaWsRtgH+ZTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgHjRvAq8fft2aG70RTOwdtkUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIF82rwPXr14fmdu7c+WcvAvzzbAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMjUZDKZrPQlAPg72BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg/wMdia5O4zef/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 36, 1)\n"
     ]
    }
   ],
   "source": [
    "display_image(x_train[0])\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(36, 36, 1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">430,800</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m430,800\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">430,224</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m430,224\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3897 - loss: 5.2435 - val_accuracy: 0.0763 - val_loss: 5.7299\n",
      "Epoch 2/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7810 - loss: 2.7834 - val_accuracy: 0.0763 - val_loss: 8.7207\n",
      "Epoch 3/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8683 - loss: 1.7525 - val_accuracy: 0.0976 - val_loss: 9.1744\n",
      "Epoch 4/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9137 - loss: 1.2344 - val_accuracy: 0.1397 - val_loss: 7.0340\n",
      "Epoch 5/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9376 - loss: 0.9449 - val_accuracy: 0.4387 - val_loss: 2.4699\n",
      "Epoch 6/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9479 - loss: 0.8043 - val_accuracy: 0.6748 - val_loss: 1.5681\n",
      "Epoch 7/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9431 - loss: 0.7458 - val_accuracy: 0.5778 - val_loss: 2.0932\n",
      "Epoch 8/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9413 - loss: 0.7233 - val_accuracy: 0.8048 - val_loss: 1.1927\n",
      "Epoch 9/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9528 - loss: 0.6898 - val_accuracy: 0.7834 - val_loss: 1.2175\n",
      "Epoch 10/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9624 - loss: 0.6253 - val_accuracy: 0.5272 - val_loss: 2.5545\n",
      "Epoch 11/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9536 - loss: 0.6222 - val_accuracy: 0.4966 - val_loss: 3.4600\n",
      "Epoch 12/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9623 - loss: 0.6266 - val_accuracy: 0.7688 - val_loss: 1.3387\n",
      "Epoch 13/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9655 - loss: 0.6017 - val_accuracy: 0.2898 - val_loss: 8.0780\n",
      "Epoch 14/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9748 - loss: 0.5127 - val_accuracy: 0.3752 - val_loss: 4.9800\n",
      "Epoch 15/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9577 - loss: 0.6095 - val_accuracy: 0.5491 - val_loss: 2.3230\n",
      "Epoch 16/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9719 - loss: 0.5574 - val_accuracy: 0.5278 - val_loss: 3.0825\n",
      "Epoch 17/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9757 - loss: 0.5108 - val_accuracy: 0.4277 - val_loss: 4.0716\n",
      "Epoch 18/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9627 - loss: 0.5837 - val_accuracy: 0.7425 - val_loss: 1.5550\n",
      "Epoch 19/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9752 - loss: 0.5586 - val_accuracy: 0.8768 - val_loss: 0.8601\n",
      "Epoch 20/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9723 - loss: 0.5380 - val_accuracy: 0.8462 - val_loss: 1.0191\n",
      "Epoch 21/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9739 - loss: 0.4985 - val_accuracy: 0.7132 - val_loss: 1.6025\n",
      "Epoch 22/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.5050 - val_accuracy: 0.6400 - val_loss: 2.0064\n",
      "Epoch 23/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9660 - loss: 0.5526 - val_accuracy: 0.7206 - val_loss: 1.6322\n",
      "Epoch 24/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9747 - loss: 0.5446 - val_accuracy: 0.5424 - val_loss: 3.4334\n",
      "Epoch 25/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9731 - loss: 0.5169 - val_accuracy: 0.7956 - val_loss: 1.1147\n",
      "Epoch 26/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9722 - loss: 0.5391 - val_accuracy: 0.6803 - val_loss: 2.2596\n",
      "Epoch 27/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9762 - loss: 0.5145 - val_accuracy: 0.3417 - val_loss: 5.2510\n",
      "Epoch 28/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.5363 - val_accuracy: 0.5394 - val_loss: 3.6389\n",
      "Epoch 29/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9775 - loss: 0.5005 - val_accuracy: 0.6894 - val_loss: 1.6961\n",
      "Epoch 30/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9801 - loss: 0.4529 - val_accuracy: 0.7297 - val_loss: 1.7410\n",
      "Epoch 31/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9764 - loss: 0.4506 - val_accuracy: 0.8700 - val_loss: 0.8443\n",
      "Epoch 32/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9734 - loss: 0.5179 - val_accuracy: 0.5772 - val_loss: 3.0085\n",
      "Epoch 33/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9801 - loss: 0.4342 - val_accuracy: 0.7053 - val_loss: 1.8364\n",
      "Epoch 34/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9841 - loss: 0.4208 - val_accuracy: 0.5815 - val_loss: 3.1104\n",
      "Epoch 35/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9797 - loss: 0.4537 - val_accuracy: 0.9128 - val_loss: 0.6767\n",
      "Epoch 36/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9700 - loss: 0.4997 - val_accuracy: 0.7328 - val_loss: 1.7825\n",
      "Epoch 37/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9731 - loss: 0.5220 - val_accuracy: 0.7730 - val_loss: 1.3049\n",
      "Epoch 38/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9792 - loss: 0.4828 - val_accuracy: 0.8877 - val_loss: 0.7946\n",
      "Epoch 39/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9756 - loss: 0.4941 - val_accuracy: 0.6754 - val_loss: 1.6927\n",
      "Epoch 40/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9833 - loss: 0.4410 - val_accuracy: 0.6852 - val_loss: 1.4573\n",
      "Epoch 41/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9818 - loss: 0.4355 - val_accuracy: 0.7523 - val_loss: 1.3794\n",
      "Epoch 42/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9788 - loss: 0.4477 - val_accuracy: 0.5412 - val_loss: 3.3025\n",
      "Epoch 43/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9820 - loss: 0.4342 - val_accuracy: 0.6229 - val_loss: 2.4836\n",
      "Epoch 44/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9807 - loss: 0.4302 - val_accuracy: 0.6687 - val_loss: 2.2201\n",
      "Epoch 45/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9764 - loss: 0.4444 - val_accuracy: 0.8597 - val_loss: 0.9417\n",
      "Epoch 46/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9788 - loss: 0.4605 - val_accuracy: 0.7462 - val_loss: 1.5138\n",
      "Epoch 47/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9784 - loss: 0.4639 - val_accuracy: 0.5119 - val_loss: 3.4129\n",
      "Epoch 48/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9816 - loss: 0.4329 - val_accuracy: 0.8066 - val_loss: 1.1250\n",
      "Epoch 49/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9812 - loss: 0.4241 - val_accuracy: 0.3954 - val_loss: 5.4153\n",
      "Epoch 50/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9785 - loss: 0.4242 - val_accuracy: 0.1495 - val_loss: 25.4988\n",
      "Epoch 51/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9821 - loss: 0.4352 - val_accuracy: 0.9079 - val_loss: 0.7368\n",
      "Epoch 52/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9820 - loss: 0.4126 - val_accuracy: 0.6278 - val_loss: 2.6044\n",
      "Epoch 53/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9812 - loss: 0.4336 - val_accuracy: 0.6620 - val_loss: 2.5604\n",
      "Epoch 54/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.4381 - val_accuracy: 0.3417 - val_loss: 8.7341\n",
      "Epoch 55/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9804 - loss: 0.4194 - val_accuracy: 0.4857 - val_loss: 3.5482\n",
      "Epoch 56/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9823 - loss: 0.3941 - val_accuracy: 0.5674 - val_loss: 3.5654\n",
      "Epoch 57/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9805 - loss: 0.3923 - val_accuracy: 0.6187 - val_loss: 2.8626\n",
      "Epoch 58/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9820 - loss: 0.4305 - val_accuracy: 0.5869 - val_loss: 3.7440\n",
      "Epoch 59/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9777 - loss: 0.4555 - val_accuracy: 0.5894 - val_loss: 2.6253\n",
      "Epoch 60/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9841 - loss: 0.4278 - val_accuracy: 0.5247 - val_loss: 3.2383\n",
      "Epoch 61/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9835 - loss: 0.3836 - val_accuracy: 0.4246 - val_loss: 6.3306\n",
      "Epoch 62/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9771 - loss: 0.4151 - val_accuracy: 0.6882 - val_loss: 2.1726\n",
      "Epoch 63/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9809 - loss: 0.4195 - val_accuracy: 0.7401 - val_loss: 1.5334\n",
      "Epoch 64/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9828 - loss: 0.3889 - val_accuracy: 0.8957 - val_loss: 0.7304\n",
      "Epoch 65/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9817 - loss: 0.4160 - val_accuracy: 0.4411 - val_loss: 4.7968\n",
      "Epoch 66/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9818 - loss: 0.4077 - val_accuracy: 0.8993 - val_loss: 0.7038\n",
      "Epoch 67/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9779 - loss: 0.4470 - val_accuracy: 0.7804 - val_loss: 1.2977\n",
      "Epoch 68/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9790 - loss: 0.4593 - val_accuracy: 0.9097 - val_loss: 0.6744\n",
      "Epoch 69/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9871 - loss: 0.3685 - val_accuracy: 0.6382 - val_loss: 2.1602\n",
      "Epoch 70/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9863 - loss: 0.3517 - val_accuracy: 0.7230 - val_loss: 1.9820\n",
      "Epoch 71/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9793 - loss: 0.3804 - val_accuracy: 0.3472 - val_loss: 10.8932\n",
      "Epoch 72/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9775 - loss: 0.4410 - val_accuracy: 0.6718 - val_loss: 2.3741\n",
      "Epoch 73/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9856 - loss: 0.3870 - val_accuracy: 0.9384 - val_loss: 0.4866\n",
      "Epoch 74/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9885 - loss: 0.3113 - val_accuracy: 0.8505 - val_loss: 0.8600\n",
      "Epoch 75/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9857 - loss: 0.3086 - val_accuracy: 0.8670 - val_loss: 0.8425\n",
      "Epoch 76/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9803 - loss: 0.3842 - val_accuracy: 0.6028 - val_loss: 2.8280\n",
      "Epoch 77/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9777 - loss: 0.4333 - val_accuracy: 0.9152 - val_loss: 0.6988\n",
      "Epoch 78/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9860 - loss: 0.3934 - val_accuracy: 0.7187 - val_loss: 1.9006\n",
      "Epoch 79/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9838 - loss: 0.3583 - val_accuracy: 0.8164 - val_loss: 1.0620\n",
      "Epoch 80/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9848 - loss: 0.3422 - val_accuracy: 0.8646 - val_loss: 0.8108\n",
      "Epoch 81/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9793 - loss: 0.3734 - val_accuracy: 0.4246 - val_loss: 5.9850\n",
      "Epoch 82/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9807 - loss: 0.3797 - val_accuracy: 0.5918 - val_loss: 2.8756\n",
      "Epoch 83/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9780 - loss: 0.4220 - val_accuracy: 0.8859 - val_loss: 0.8209\n",
      "Epoch 84/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9843 - loss: 0.3729 - val_accuracy: 0.6022 - val_loss: 2.8994\n",
      "Epoch 85/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9881 - loss: 0.3571 - val_accuracy: 0.9426 - val_loss: 0.5031\n",
      "Epoch 86/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9827 - loss: 0.3401 - val_accuracy: 0.7169 - val_loss: 1.8165\n",
      "Epoch 87/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9819 - loss: 0.3516 - val_accuracy: 0.7413 - val_loss: 1.6259\n",
      "Epoch 88/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9900 - loss: 0.3222 - val_accuracy: 0.6229 - val_loss: 2.9457\n",
      "Epoch 89/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9856 - loss: 0.3223 - val_accuracy: 0.9341 - val_loss: 0.5723\n",
      "Epoch 90/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9767 - loss: 0.4065 - val_accuracy: 0.5644 - val_loss: 3.6193\n",
      "Epoch 91/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9865 - loss: 0.3389 - val_accuracy: 0.6980 - val_loss: 2.2772\n",
      "Epoch 92/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9855 - loss: 0.3409 - val_accuracy: 0.7120 - val_loss: 1.8293\n",
      "Epoch 93/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9844 - loss: 0.3197 - val_accuracy: 0.7614 - val_loss: 1.3836\n",
      "Epoch 94/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9831 - loss: 0.3513 - val_accuracy: 0.8621 - val_loss: 0.9840\n",
      "Epoch 95/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9854 - loss: 0.3466 - val_accuracy: 0.6144 - val_loss: 2.5619\n",
      "Epoch 96/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9845 - loss: 0.3468 - val_accuracy: 0.8267 - val_loss: 0.9742\n",
      "Epoch 97/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9814 - loss: 0.3816 - val_accuracy: 0.8566 - val_loss: 0.8368\n",
      "Epoch 98/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9816 - loss: 0.3776 - val_accuracy: 0.2855 - val_loss: 9.5395\n",
      "Epoch 99/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9826 - loss: 0.3833 - val_accuracy: 0.4930 - val_loss: 4.3885\n",
      "Epoch 100/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9890 - loss: 0.3169 - val_accuracy: 0.9048 - val_loss: 0.6131\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('adv_model-3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(r'adv_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(28, 28)):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    img_array = img_array.reshape((1, target_size[0], target_size[1], 1))\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_folder(base_folder):\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_label = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'add','dec'\n",
    "#       'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
    "index_to_label = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'add', 'mul', 'sub', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    predictions = loaded_model.predict(img_array,verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    print(index_to_label[predicted_class[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = r'C:\\Users\\salos\\MathPad-Solver\\test-digit'\n",
    "for file_path in list_files_in_folder(base_folder):\n",
    "    img_array = preprocess_image(file_path)\n",
    "    predictions = loaded_model.predict(img_array,verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    print(index_to_label[predicted_class[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub\n"
     ]
    }
   ],
   "source": [
    "img_array = predict_image(r'C:\\Users\\salos\\MathPad-Solver\\recognition\\custom_model\\datasets\\sub\\xrCP3RgB.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathsolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
